{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9441a15f-a0d6-4b97-b3af-f6f76deeb657",
   "metadata": {},
   "source": [
    "# Model Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e927b1b-1de5-4ddb-ab2a-4fb5e62ba562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.12/site-packages (2.6.0)\n",
      "Requirement already satisfied: datasets in /opt/anaconda3/lib/python3.12/site-packages (3.6.0)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (4.66.5)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.12/site-packages (1.5.1)\n",
      "Requirement already satisfied: tokenizers in /opt/anaconda3/lib/python3.12/site-packages (0.21.1)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: xxhash in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (0.33.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/anaconda3/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10.5)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.24.0->datasets) (1.1.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.11.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch datasets pandas numpy tqdm scikit-learn tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5445b864-6c87-4e48-ac08-33f12aa31335",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordPiece\n",
    "from tokenizers.trainers import WordPieceTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "39b9a79d-156d-4524-ac4d-349ee2a87ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable tokenizer parallelism\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a8e955e-7cb8-4240-b9aa-98a990cac691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7903d23d-9326-4c10-9cf6-17d2374918b1",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "92d76cfb-308e-4c43-b36e-5c27adb81fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label counts: {0: 9500, 1: 9500}\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"cholito_bengali_human_ai_dataset.csv\")\n",
    "label_map = {\"human\": 0, \"ai\": 1}\n",
    "df[\"label\"] = df[\"label\"].map(label_map)\n",
    "texts = df[\"text\"].tolist()\n",
    "labels = df[\"label\"].tolist()\n",
    "print(f\"Label counts: {pd.Series(labels).value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c28e29b-6df1-4ff4-b342-219c4b1c1875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train label counts: {1: 7600, 0: 7600}\n",
      "Validation label counts: {1: 950, 0: 950}\n",
      "Test label counts: {1: 950, 0: 950}\n"
     ]
    }
   ],
   "source": [
    "# Data Splitting\n",
    "train_texts, temp_texts, train_labels, temp_labels = train_test_split(\n",
    "    texts, labels, test_size=0.2, stratify=labels, random_state=42\n",
    ")\n",
    "val_texts, test_texts, val_labels, test_labels = train_test_split(\n",
    "    temp_texts, temp_labels, test_size=0.5, stratify=temp_labels, random_state=42\n",
    ")\n",
    "print(f\"Train label counts: {pd.Series(train_labels).value_counts().to_dict()}\")\n",
    "print(f\"Validation label counts: {pd.Series(val_labels).value_counts().to_dict()}\")\n",
    "print(f\"Test label counts: {pd.Series(test_labels).value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16a9d35-acfd-4b47-b955-d2cee6ac2b9e",
   "metadata": {},
   "source": [
    "# Custom Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1759ec2f-d771-43e4-b9a4-a161f893e446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(WordPiece(unk_token=\"[UNK]\"))\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "trainer = WordPieceTrainer(vocab_size=30000, special_tokens=[\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\"])\n",
    "tokenizer.train_from_iterator(train_texts, trainer)\n",
    "tokenizer.save(\"bengali_wordpiece_tokenizer.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "65a5d12a-4698-4aa6-9318-8056f7cd184b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize\n",
    "def tokenize_texts(texts, tokenizer, max_length=128):\n",
    "    encodings = tokenizer.encode_batch(texts)\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    for enc in encodings:\n",
    "        ids = enc.ids[:max_length] if len(enc.ids) > max_length else enc.ids + [0] * (max_length - len(enc.ids))\n",
    "        mask = [1] * len(enc.ids[:max_length]) + [0] * (max_length - len(enc.ids[:max_length]))\n",
    "        input_ids.append(ids)\n",
    "        attention_masks.append(mask)\n",
    "    return {\n",
    "        \"input_ids\": torch.tensor(input_ids, dtype=torch.long),\n",
    "        \"attention_mask\": torch.tensor(attention_masks, dtype=torch.long)\n",
    "    }\n",
    "train_encodings = tokenize_texts(train_texts, tokenizer)\n",
    "val_encodings = tokenize_texts(val_texts, tokenizer)\n",
    "test_encodings = tokenize_texts(test_texts, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "01a1a173-67fc-4fc9-bdfc-6418f10e159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "class BengaliTextDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "train_dataset = BengaliTextDataset(train_encodings, train_labels)\n",
    "val_dataset = BengaliTextDataset(val_encodings, val_labels)\n",
    "test_dataset = BengaliTextDataset(test_encodings, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a63dacb1-28aa-4cf6-a7d7-7c4ba726efcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataloader\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff3c558-0bf0-466e-92f1-0ab8159774a7",
   "metadata": {},
   "source": [
    "# Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1a801d5b-d372-4698-a7b4-3b6b8ddd7b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1), :]\n",
    "\n",
    "class CustomTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model=256, nhead=8, num_encoder_layers=4, dim_feedforward=512, num_classes=2):\n",
    "        super(CustomTransformer, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward, batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_encoder_layers)\n",
    "        self.fc = nn.Linear(d_model, num_classes)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        x = self.embedding(input_ids) * math.sqrt(self.d_model)\n",
    "        x = self.pos_encoder(x)\n",
    "        if attention_mask is not None:\n",
    "            # Convert attention mask: 1 (valid token) -> False, 0 (padding) -> True\n",
    "            key_padding_mask = (attention_mask == 0)\n",
    "            x = self.transformer_encoder(x, src_key_padding_mask=key_padding_mask)\n",
    "        else:\n",
    "            x = self.transformer_encoder(x)\n",
    "        x = x[:, 0, :]  # Use [CLS] token representation\n",
    "        return self.fc(x)\n",
    "\n",
    "# Initialize model\n",
    "vocab_size = tokenizer.get_vocab_size()\n",
    "model = CustomTransformer(vocab_size=vocab_size)\n",
    "model.to(device)\n",
    "\n",
    "# Optimizer and scheduler\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "num_epochs = 10\n",
    "total_steps = len(train_loader) * num_epochs\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab9706d-5829-4e26-bc11-f9bde85685cb",
   "metadata": {},
   "source": [
    "# Set up Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e5c86f2f-9209-406b-b19c-d5b9b3035761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and evaluation functions\n",
    "def train_epoch(model, data_loader, optimizer, device, scheduler):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(data_loader, desc=\"Training\", unit=\"batch\")\n",
    "    for batch in progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        progress_bar.set_postfix({\"loss\": loss.item()})\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "def evaluate(model, data_loader, device, desc=\"Evaluating\"):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    progress_bar = tqdm(data_loader, desc=desc, unit=\"batch\")\n",
    "    with torch.no_grad():\n",
    "        for batch in progress_bar:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "            progress_bar.set_postfix({\"loss\": loss.item()})\n",
    "\n",
    "    predictions = np.array(predictions)\n",
    "    true_labels = np.array(true_labels)\n",
    "    accuracy = np.mean(predictions == true_labels)\n",
    "    cm = np.zeros((2, 2), dtype=int)\n",
    "    for t, p in zip(true_labels, predictions):\n",
    "        cm[t, p] += 1\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    return {\n",
    "        \"loss\": total_loss / len(data_loader),\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"confusion_matrix\": cm.tolist()\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bad6bd-4a4a-4b5c-b422-61c69f310362",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e33e4a81-4a9f-4ffa-96b6-a55d51c2e95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████| 950/950 [06:05<00:00,  2.60batch/s, loss=0.73]\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py:508: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/NestedTensorImpl.cpp:182.)\n",
      "  output = torch._nested_tensor_from_mask(\n",
      "Validating: 100%|██████████████| 119/119 [00:09<00:00, 11.96batch/s, loss=0.909]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6927\n",
      "Validation Metrics: Loss: 0.6939, Accuracy: 0.5563, Precision: 0.5554, Recall: 0.5642, F1: 0.5598\n",
      "Confusion Matrix:\n",
      "[[521 429]\n",
      " [414 536]]\n",
      "\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████| 950/950 [05:46<00:00,  2.74batch/s, loss=0.726]\n",
      "Validating: 100%|██████████████| 119/119 [00:10<00:00, 11.17batch/s, loss=0.909]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6910\n",
      "Validation Metrics: Loss: 0.6939, Accuracy: 0.5563, Precision: 0.5554, Recall: 0.5642, F1: 0.5598\n",
      "Confusion Matrix:\n",
      "[[521 429]\n",
      " [414 536]]\n",
      "\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████| 950/950 [05:58<00:00,  2.65batch/s, loss=0.866]\n",
      "Validating: 100%|██████████████| 119/119 [00:10<00:00, 11.29batch/s, loss=0.909]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6917\n",
      "Validation Metrics: Loss: 0.6939, Accuracy: 0.5563, Precision: 0.5554, Recall: 0.5642, F1: 0.5598\n",
      "Confusion Matrix:\n",
      "[[521 429]\n",
      " [414 536]]\n",
      "\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████| 950/950 [05:34<00:00,  2.84batch/s, loss=0.755]\n",
      "Validating: 100%|██████████████| 119/119 [00:05<00:00, 20.06batch/s, loss=0.909]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6939\n",
      "Validation Metrics: Loss: 0.6939, Accuracy: 0.5563, Precision: 0.5554, Recall: 0.5642, F1: 0.5598\n",
      "Confusion Matrix:\n",
      "[[521 429]\n",
      " [414 536]]\n",
      "\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████| 950/950 [03:26<00:00,  4.60batch/s, loss=0.741]\n",
      "Validating: 100%|██████████████| 119/119 [00:06<00:00, 17.41batch/s, loss=0.909]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6937\n",
      "Validation Metrics: Loss: 0.6939, Accuracy: 0.5563, Precision: 0.5554, Recall: 0.5642, F1: 0.5598\n",
      "Confusion Matrix:\n",
      "[[521 429]\n",
      " [414 536]]\n",
      "\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████| 950/950 [03:30<00:00,  4.52batch/s, loss=0.825]\n",
      "Validating: 100%|██████████████| 119/119 [00:06<00:00, 18.17batch/s, loss=0.909]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6944\n",
      "Validation Metrics: Loss: 0.6939, Accuracy: 0.5563, Precision: 0.5554, Recall: 0.5642, F1: 0.5598\n",
      "Confusion Matrix:\n",
      "[[521 429]\n",
      " [414 536]]\n",
      "\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████| 950/950 [03:34<00:00,  4.44batch/s, loss=0.714]\n",
      "Validating: 100%|██████████████| 119/119 [00:06<00:00, 18.08batch/s, loss=0.909]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6925\n",
      "Validation Metrics: Loss: 0.6939, Accuracy: 0.5563, Precision: 0.5554, Recall: 0.5642, F1: 0.5598\n",
      "Confusion Matrix:\n",
      "[[521 429]\n",
      " [414 536]]\n",
      "\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████| 950/950 [03:34<00:00,  4.42batch/s, loss=0.728]\n",
      "Validating: 100%|██████████████| 119/119 [00:06<00:00, 18.18batch/s, loss=0.909]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6940\n",
      "Validation Metrics: Loss: 0.6939, Accuracy: 0.5563, Precision: 0.5554, Recall: 0.5642, F1: 0.5598\n",
      "Confusion Matrix:\n",
      "[[521 429]\n",
      " [414 536]]\n",
      "\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████| 950/950 [03:32<00:00,  4.48batch/s, loss=0.688]\n",
      "Validating: 100%|██████████████| 119/119 [00:06<00:00, 19.22batch/s, loss=0.909]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6929\n",
      "Validation Metrics: Loss: 0.6939, Accuracy: 0.5563, Precision: 0.5554, Recall: 0.5642, F1: 0.5598\n",
      "Confusion Matrix:\n",
      "[[521 429]\n",
      " [414 536]]\n",
      "\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████| 950/950 [03:27<00:00,  4.57batch/s, loss=0.721]\n",
      "Validating: 100%|██████████████| 119/119 [00:07<00:00, 15.33batch/s, loss=0.909]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6937\n",
      "Validation Metrics: Loss: 0.6939, Accuracy: 0.5563, Precision: 0.5554, Recall: 0.5642, F1: 0.5598\n",
      "Confusion Matrix:\n",
      "[[521 429]\n",
      " [414 536]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, device, scheduler)\n",
    "    val_metrics = evaluate(model, val_loader, device, desc=\"Validating\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"Validation Metrics: Loss: {val_metrics['loss']:.4f}, Accuracy: {val_metrics['accuracy']:.4f}, \"\n",
    "          f\"Precision: {val_metrics['precision']:.4f}, Recall: {val_metrics['recall']:.4f}, F1: {val_metrics['f1']:.4f}\")\n",
    "    print(f\"Confusion Matrix:\\n{np.array(val_metrics['confusion_matrix'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a37d9a7e-6e7b-4db6-b705-77878e381a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|█████████████████| 119/119 [00:07<00:00, 16.00batch/s, loss=0.611]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Metrics: Loss: 0.7027, Accuracy: 0.5479, Precision: 0.5462, Recall: 0.5663, F1: 0.5561\n",
      "Confusion Matrix:\n",
      "[[503 447]\n",
      " [412 538]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test evaluation\n",
    "test_metrics = evaluate(model, test_loader, device, desc=\"Testing\")\n",
    "print(f\"\\nTest Metrics: Loss: {test_metrics['loss']:.4f}, Accuracy: {test_metrics['accuracy']:.4f}, \"\n",
    "      f\"Precision: {test_metrics['precision']:.4f}, Recall: {test_metrics['recall']:.4f}, F1: {test_metrics['f1']:.4f}\")\n",
    "print(f\"Confusion Matrix:\\n{np.array(test_metrics['confusion_matrix'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2b35259b-9ff8-4930-9be8-bbd55efef193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to 'bengali_custom_transformer.pt' and tokenizer saved to 'bengali_wordpiece_tokenizer.json'\n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "torch.save(model.state_dict(), \"bengali_custom_transformer.pt\")\n",
    "tokenizer.save(\"bengali_wordpiece_tokenizer.json\")\n",
    "print(\"Model saved to 'bengali_custom_transformer.pt' and tokenizer saved to 'bengali_wordpiece_tokenizer.json'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f5ee15-1635-4d57-b236-43a2378e5757",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c961a96-eb74-457c-9353-17fe67a17214",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97f211b2-4467-46f9-9b7f-b1a518701a3f",
   "metadata": {},
   "source": [
    "# Another One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "964ab124-4a47-41e2-8a70-686177299b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b3f091e-2b99-4986-a948-931c9db568cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "batch_size = 32\n",
    "max_length = 128\n",
    "num_epochs = 20\n",
    "learning_rate = 3e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "743809cf-c897-4b07-930f-2683e33479fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cholito_bengali_human_ai_dataset.csv\")\n",
    "df = df[df['label'].isin(['human', 'ai'])]  # Filter unwanted labels\n",
    "label_map = {\"human\": 0, \"ai\": 1}\n",
    "df[\"label\"] = df[\"label\"].map(label_map)\n",
    "texts, labels = df[\"text\"].tolist(), df[\"label\"].tolist()\n",
    "\n",
    "train_texts, temp_texts, train_labels, temp_labels = train_test_split(texts, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "val_texts, test_texts, val_labels, test_labels = train_test_split(temp_texts, temp_labels, test_size=0.5, stratify=temp_labels, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb96160-bbca-4fff-9ff1-b37e201b0910",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c110e82f-0b4b-416c-904a-8e095a9568ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"bengali_tokenizer\"):\n",
    "    os.makedirs(\"bengali_tokenizer\")  # Ensure the directory exists\n",
    "    tokenizer = ByteLevelBPETokenizer()\n",
    "    tokenizer.train_from_iterator(train_texts, vocab_size=30000, min_frequency=2, special_tokens=[\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\"])\n",
    "    tokenizer.save_model(\"bengali_tokenizer\")\n",
    "else:\n",
    "    tokenizer = ByteLevelBPETokenizer(\"bengali_tokenizer/vocab.json\", \"bengali_tokenizer/merges.txt\")\n",
    "\n",
    "def encode_batch(texts):\n",
    "    encodings = tokenizer.encode_batch(texts)\n",
    "    input_ids, attention_masks = [], []\n",
    "    for e in encodings:\n",
    "        ids = e.ids[:max_length] + [0] * (max_length - len(e.ids)) if len(e.ids) < max_length else e.ids[:max_length]\n",
    "        mask = [1] * min(len(e.ids), max_length) + [0] * (max_length - len(e.ids))\n",
    "        input_ids.append(ids)\n",
    "        attention_masks.append(mask)\n",
    "    return torch.tensor(input_ids), torch.tensor(attention_masks)\n",
    "\n",
    "class BengaliTextDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.input_ids, self.attention_mask = encode_batch(texts)\n",
    "        self.labels = torch.tensor(labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": self.input_ids[idx],\n",
    "            \"attention_mask\": self.attention_mask[idx],\n",
    "            \"labels\": self.labels[idx]\n",
    "        }\n",
    "\n",
    "train_dataset = BengaliTextDataset(train_texts, train_labels)\n",
    "val_dataset = BengaliTextDataset(val_texts, val_labels)\n",
    "test_dataset = BengaliTextDataset(test_texts, test_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e19eaf4-f0f1-4f66-ab22-a058cc6d4a5e",
   "metadata": {},
   "source": [
    "# Custom Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d55bb90-62f8-4ce3-ace6-70581202eb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size, max_len=128, d_model=512, nhead=8, num_layers=6, dim_feedforward=2048, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.position_embedding = nn.Embedding(max_len, d_model)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model, nhead, dim_feedforward, dropout=0.3, batch_first=True)\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(d_model, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        positions = torch.arange(0, input_ids.size(1), device=input_ids.device).unsqueeze(0)\n",
    "        x = self.embedding(input_ids) + self.position_embedding(positions)\n",
    "        x = self.encoder(x, src_key_padding_mask=~attention_mask.bool())\n",
    "        x = self.dropout(x[:, 0])  # Take CLS token representation\n",
    "        return self.classifier(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa0f24b-efc8-44ce-8258-0ccc7af5df44",
   "metadata": {},
   "source": [
    "# Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c726c0a5-8421-4766-bfd8-161dee1fb754",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = tokenizer.get_vocab_size()\n",
    "model = CustomTransformer(vocab_size=vocab_size).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "# Scheduler (optional warmup + decay)\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "warmup_steps = 500\n",
    "total_steps = len(train_loader) * num_epochs\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, warmup_steps, total_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "830bfe40-b38a-476c-af4e-f3712518c041",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(train_loader, desc=\"Training\"):\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    accuracy = np.mean(np.array(all_preds) == np.array(all_labels))\n",
    "    return total_loss / len(loader), accuracy, all_preds, all_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec91239-779f-41ad-aa1a-9b0cb6ab8252",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d40f9cc-db01-47ff-bf16-217478166a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 475/475 [00:35<00:00, 13.24it/s]\n",
      "C:\\Users\\Jim\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:508: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\NestedTensorImpl.cpp:182.)\n",
      "  output = torch._nested_tensor_from_mask(\n",
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 45.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4713, Val Loss: 0.3383, Val Acc: 0.9253\n",
      "Saved new best model.\n",
      "\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 475/475 [00:34<00:00, 13.62it/s]\n",
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 49.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3432, Val Loss: 0.3975, Val Acc: 0.9158\n",
      "\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 475/475 [00:34<00:00, 13.62it/s]\n",
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 49.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3293, Val Loss: 0.3243, Val Acc: 0.9421\n",
      "Saved new best model.\n",
      "\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 475/475 [00:35<00:00, 13.54it/s]\n",
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 49.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3263, Val Loss: 0.4588, Val Acc: 0.8684\n",
      "\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 475/475 [00:34<00:00, 13.58it/s]\n",
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 48.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4169, Val Loss: 0.4304, Val Acc: 0.8758\n",
      "\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 475/475 [00:34<00:00, 13.58it/s]\n",
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 49.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4536, Val Loss: 0.4066, Val Acc: 0.8853\n",
      "\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 475/475 [00:34<00:00, 13.62it/s]\n",
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 49.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4086, Val Loss: 0.5014, Val Acc: 0.8363\n",
      "\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 475/475 [00:34<00:00, 13.64it/s]\n",
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 49.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5246, Val Loss: 0.8762, Val Acc: 0.5458\n",
      "\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 475/475 [00:34<00:00, 13.62it/s]\n",
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 49.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5661, Val Loss: 0.9056, Val Acc: 0.6221\n",
      "\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 475/475 [00:34<00:00, 13.65it/s]\n",
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 49.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5158, Val Loss: 1.1524, Val Acc: 0.5011\n",
      "\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 475/475 [00:34<00:00, 13.62it/s]\n",
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 49.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5776, Val Loss: 0.8540, Val Acc: 0.5047\n",
      "\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 475/475 [00:34<00:00, 13.59it/s]\n",
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 48.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5469, Val Loss: 0.5872, Val Acc: 0.7816\n",
      "\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 475/475 [00:34<00:00, 13.64it/s]\n",
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 49.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4185, Val Loss: 0.4050, Val Acc: 0.8768\n",
      "\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 475/475 [00:34<00:00, 13.62it/s]\n",
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 49.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3926, Val Loss: 0.4127, Val Acc: 0.8805\n",
      "\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 475/475 [00:34<00:00, 13.64it/s]\n",
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 48.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3578, Val Loss: 0.3850, Val Acc: 0.9047\n",
      "\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 475/475 [00:34<00:00, 13.62it/s]\n",
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 49.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3383, Val Loss: 0.3790, Val Acc: 0.9079\n",
      "\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 475/475 [00:34<00:00, 13.64it/s]\n",
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 49.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3280, Val Loss: 0.3750, Val Acc: 0.9032\n",
      "\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 475/475 [00:34<00:00, 13.62it/s]\n",
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 49.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3218, Val Loss: 0.3500, Val Acc: 0.9158\n",
      "\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 475/475 [00:34<00:00, 13.62it/s]\n",
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 49.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3173, Val Loss: 0.3541, Val Acc: 0.9168\n",
      "\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 475/475 [00:34<00:00, 13.65it/s]\n",
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 49.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3155, Val Loss: 0.3537, Val Acc: 0.9158\n",
      "\n",
      "Final Evaluation on Test Set:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 49.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.3547, Test Accuracy: 0.9116\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'confusion_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Test Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Confusion Matrix\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m cm \u001b[38;5;241m=\u001b[39m confusion_matrix(test_labels, test_preds)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mConfusion Matrix:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(cm)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'confusion_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "best_val_acc = 0.0\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    train_loss = train_epoch()\n",
    "    val_loss, val_acc, _, _ = evaluate(val_loader)\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # Save model if it improves\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_bengali_transformer.pt\")\n",
    "        print(\"Saved new best model.\")\n",
    "\n",
    "# Test\n",
    "print(\"\\nFinal Evaluation on Test Set:\")\n",
    "test_loss, test_acc, test_preds, test_labels = evaluate(test_loader)\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5d86588-2897-46ab-88e7-91b3adbebfcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 42.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.3359, Test Accuracy: 0.9363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Load best model weights\n",
    "model.load_state_dict(torch.load(\"best_bengali_transformer.pt\"))\n",
    "model.eval()\n",
    "\n",
    "# Evaluate on test set\n",
    "test_loss, test_acc, test_preds, test_labels = evaluate(test_loader)\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ccfa841-ea6c-4d58-9ea8-0be159d6eda1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       human     0.9359    0.9368    0.9363       950\n",
      "          AI     0.9368    0.9358    0.9363       950\n",
      "\n",
      "    accuracy                         0.9363      1900\n",
      "   macro avg     0.9363    0.9363    0.9363      1900\n",
      "weighted avg     0.9363    0.9363    0.9363      1900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert predictions and labels to numpy arrays (if not already)\n",
    "test_preds = test_preds.cpu().numpy() if hasattr(test_preds, \"cpu\") else test_preds\n",
    "test_labels = test_labels.cpu().numpy() if hasattr(test_labels, \"cpu\") else test_labels\n",
    "\n",
    "# Define class names\n",
    "class_names = [\"human\", \"AI\"]\n",
    "\n",
    "# Plot confusion matrix with labels\n",
    "cm = confusion_matrix(test_labels, test_preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "disp.plot(cmap='Blues', xticks_rotation=45)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Print classification report with label names\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(test_labels, test_preds, target_names=class_names, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd28eab9-bab7-4a9e-9629-48a976e542e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
