{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7015b42c",
   "metadata": {},
   "source": [
    "# Import Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215740ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from transformers import TrainingArguments, Trainer, DataCollatorForSeq2Seq\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "df = pd.read_csv(\"../final_dataset.csv\")\n",
    "df['label'] = df['label'].map({'human': 0, 'ai': 1})\n",
    "\n",
    "#split data\n",
    "train_texts, temp_texts, train_labels, temp_labels = train_test_split(\n",
    "    df['text'].tolist(), df['label'].tolist(),\n",
    "    test_size=0.2, stratify=df['label'], random_state=42\n",
    ")\n",
    "\n",
    "val_texts, test_texts, val_labels, test_labels = train_test_split(\n",
    "    temp_texts, temp_labels,\n",
    "    test_size=0.5, stratify=temp_labels, random_state=42\n",
    ")\n",
    "splits = {\n",
    "    \"Train\": train_labels,\n",
    "    \"Validation\": val_labels,\n",
    "    \"Test\": test_labels,\n",
    "}\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "for i, (split_name, split_labels) in enumerate(splits.items()):\n",
    "    counts = pd.Series(split_labels).value_counts().sort_index()\n",
    "    class_names = ['Human', 'AI']\n",
    "    sns.barplot(x=class_names, y=counts.values, ax=axs[i], palette=\"pastel\")\n",
    "    axs[i].set_title(f\"{split_name} Set\")\n",
    "    axs[i].set_ylabel(\"Count\")\n",
    "    axs[i].set_ylim(0, max(counts.values) * 1.2)\n",
    "    for j, count in enumerate(counts.values):\n",
    "        axs[i].text(j, count + 2, str(count), ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"Label Distribution Across Splits\", fontsize=16, y=1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ea5c3b-e909-424d-8bc9-dd4cbe69767b",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57da1f3-959f-4ba8-95ed-a68fa9a104a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"sagorsarker/bangla-gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=256)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=256)\n",
    "test_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=256)\n",
    "\n",
    "class BengaliDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            key: torch.tensor(val[idx]) for key, val in self.encodings.items()\n",
    "        } | {'labels': torch.tensor(self.labels[idx])}\n",
    "\n",
    "train_dataset = BengaliDataset(train_encodings, train_labels)\n",
    "val_dataset = BengaliDataset(val_encodings, val_labels)\n",
    "test_dataset = BengaliDataset(test_encodings, test_labels)\n",
    "\n",
    "#Evaluation metrics\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"binary\")\n",
    "    return {\"accuracy\": acc, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8931b3ab-3059-4f82-a34e-0e9d23a2ed38",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad3f4c4-5457-4626-9521-5b9733b16835",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training args\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./banglagpt2_results\",\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    weight_decay=0.01,\n",
    "    report_to=\"none\",\n",
    "    seed=42,\n",
    "    disable_tqdm=False,\n",
    ")\n",
    "\n",
    "#Trainer\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ef56cd-46dd-41bf-ab7e-46f1f0a746be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logs\n",
    "logs = trainer.state.log_history\n",
    "\n",
    "train_loss, val_loss, train_acc, val_acc, epochs = [], [], [], [], []\n",
    "\n",
    "for log in logs:\n",
    "    if \"epoch\" in log:\n",
    "        if \"loss\" in log and \"eval_loss\" not in log:\n",
    "            train_loss.append(log[\"loss\"])\n",
    "            epochs.append(log[\"epoch\"])\n",
    "        if \"eval_loss\" in log:\n",
    "            val_loss.append(log[\"eval_loss\"])\n",
    "            val_acc.append(log[\"eval_accuracy\"])\n",
    "        if \"train_accuracy\" in log:\n",
    "            train_acc.append(log[\"train_accuracy\"])\n",
    "if not train_acc:\n",
    "    train_preds_output = trainer.predict(train_dataset)\n",
    "    train_preds = np.argmax(train_preds_output.predictions, axis=-1)\n",
    "    train_acc_value = accuracy_score(train_preds_output.label_ids, train_preds)\n",
    "    train_acc = [train_acc_value] * len(val_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d56ac15-fbae-4933-90cc-6187ef97c22f",
   "metadata": {},
   "source": [
    "# Curves Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b0f764-6494-49aa-b4f2-d384fca2d264",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss Curve\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(epochs, train_loss, label=\"Training Loss\", marker=\"o\")\n",
    "plt.plot(epochs, val_loss, label=\"Validation Loss\", marker=\"o\")\n",
    "best_epoch = np.argmin(val_loss)\n",
    "plt.axvline(epochs[best_epoch], color=\"red\", linestyle=\"dotted\", label=\"Best Epoch\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Training vs Validation Loss\")\n",
    "plt.show()\n",
    "\n",
    "#Accuracy Curve\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(epochs, train_acc, label=\"Training Accuracy\", marker=\"o\")\n",
    "plt.plot(epochs, val_acc, label=\"Validation Accuracy\", marker=\"o\")\n",
    "best_epoch_acc = np.argmax(val_acc)\n",
    "plt.axvline(epochs[best_epoch_acc], color=\"red\", linestyle=\"dotted\", label=\"Best Epoch\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Training vs Validation Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa48a4e-97d5-43c5-84c8-2042ecd59c39",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4563b2af-8bb6-452f-957e-f0b01aa0594e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_output = trainer.predict(test_dataset)\n",
    "preds = np.argmax(preds_output.predictions, axis=-1)\n",
    "\n",
    "#Confusion Matrix\n",
    "cm = confusion_matrix(test_labels, preds, labels=[0,1])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Human\",\"AI\"])\n",
    "disp.plot(cmap=\"Blues\", values_format=\"d\")\n",
    "plt.title(\"Confusion Matrix (Test Set)\")\n",
    "plt.show()\n",
    "report = classification_report(test_labels, preds, target_names=[\"Human\", \"AI\"], digits=4)\n",
    "print(\"Classification Report (Test Set):\\n\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08798d73-8da2-4965-89bc-8fa5790c640f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the best model\n",
    "trainer.save_model(\"./banglagpt2_model\")\n",
    "tokenizer.save_pretrained(\"./banglagpt2_tokenizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe899ce-7178-4404-9d0e-60efa5322bf9",
   "metadata": {},
   "source": [
    "# About Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df99818-fe39-4698-8112-4b308a4f5ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig\n",
    "print(\"\\nModel architecture:\")\n",
    "print(model)\n",
    "\n",
    "#Parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Non-trainable parameters: {total_params - trainable_params:,}\")\n",
    "\n",
    "config = AutoConfig.from_pretrained(\"sagorsarker/bangla-gpt2\")\n",
    "print(\"\\nModel configuration:\")\n",
    "print(config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
